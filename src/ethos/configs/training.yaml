model_type: "decoder"
data_fp: "ethos_data"
val_size: 0.1
out_dir: "gpu_model"
eval_interval: 1000
log_interval: 10
resume: false
# logging
wandb_log: false
wandb_project: "ethos"
wandb_run_name: "ethos_run"
# training parameters
gradient_accumulation_steps: 4
batch_size: 32
# model parameters
n_positions: 1024
n_layer: 6
n_head: 12
n_embd: 384
dropout: 0.1
activation: "gelu"
# optimizer parameters
max_iters: 50000
lr: 0.0003 # Learning rate
weight_decay: 0.1
beta1: 0.9
beta2: 0.95
grad_clip: 1.0
# learning rate schedule
warmup_iters: 2000
lr_decay_iters: 25000
min_lr: 0.00003
# system
backend: "nccl" # "nccl", "gloo"
device: "cuda" # "cuda", "cpu"
dtype: "bfloat16" # "float32", "bfloat16", "float16"
no_compile: false

hydra:
  output_subdir: null
