model_type: "decoder"
data_fp: "ethos_data"
val_size: 0.1
out_dir: "cpu_test_model"
eval_interval: 100
log_interval: 10
resume: false
# logging
wandb_log: false
wandb_project: "ethos"
wandb_run_name: "ethos_run"
# training parameters
gradient_accumulation_steps: 8
batch_size: 4
# model parameters
n_positions: 256
n_layer: 2
n_head: 4
n_embd: 128
dropout: 0
activation: "gelu"
# optimizer parameters
max_iters: 500
lr: 0.0001 # Learning rate
weight_decay: 0.1
beta1: 0.9
beta2: 0.95
grad_clip: 1.0
# learning rate schedule
warmup_iters: 100
lr_decay_iters: 250
min_lr: 0.00001
# system
backend: "nccl" # "nccl", "gloo"
device: "cpu" # "cuda", "cpu"
dtype: "float32" # "float32", "bfloat16", "float16"
no_compile: false

hydra:
  output_subdir: null
